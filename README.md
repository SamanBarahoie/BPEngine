
# ğŸ§  C++ Tokenizer with Python Binding

This project implements a custom **Byte Pair Encoding (BPE) tokenizer** in C++, and exposes it to Python using **pybind11**. It's designed for performance, educational clarity, and easy integration with machine learning workflows.

---

## ğŸ“¦ Features

- ğŸ”¤ Byte Pair Encoding (BPE) tokenizer
- âš¡ Fast C++ implementation
- ğŸ”— Python binding via pybind11
- ğŸ“š JSON-based vocabulary/merges I/O (via `nlohmann/json`)
- ğŸ§ª Easy to integrate with Jupyter, NumPy, and PyTorch

---

## ğŸ› ï¸ Build Instructions

### ğŸ”§ Requirements

- [CMake](https://cmake.org/) â‰¥ 3.14
- [Ninja](https://ninja-build.org/)
- C++17 compiler (e.g. g++, clang++)
- Python â‰¥ 3.6 (Python 3.10 or below recommended for compatibility)
- Optional: `pybind11`, `nlohmann/json` (included in `extern/`)

---

### ğŸ“ Folder Structure

```
tokenizer_project/
â”œâ”€â”€ CMakeLists.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Tokenizer.cpp
â”‚   â”œâ”€â”€ Tokenizer.hpp
â”‚   â””â”€â”€ bindings.cpp
â”œâ”€â”€ extern/
â”‚   â”œâ”€â”€ pybind11/          # from https://github.com/pybind/pybind11
â”‚   â””â”€â”€ nlohmann/json.hpp  # from https://github.com/nlohmann/json
â””â”€â”€ build/                 # (created after build)
```

---

### ğŸš€ Building the Project

```bash
# 1. Clone this repo and cd into it
cd tokenizer_project

# 2. Create the build directory
mkdir build && cd build

# 3. Configure with CMake and Ninja
cmake .. -G Ninja

# 4. Build the project
ninja
```

After building, a shared object will be created, e.g. `pytokenizer.*.pyd`, which can be imported in Python:

```python
import pytokenizer

tokenizer = pytokenizer.Tokenizer()
ids = tokenizer.encode_to_ids("hello world")
print(ids)
```

---

## ğŸ§  Example Usage (Python)

```python
from pytokenizer import Tokenizer

tokenizer = Tokenizer()
tokenizer.train(["this is a test", "tokenize this sentence"], vocab_size=100)

ids = tokenizer.encode_to_ids("tokenize this")
print("Encoded IDs:", ids)

tokenizer.save_vocab("vocab.json")
tokenizer.save_merges("merges.txt")
```

---

## ğŸ“œ License

This project is licensed under the MIT License.

---

## ğŸ™Œ Credits

- [pybind11](https://github.com/pybind/pybind11)
- [nlohmann/json](https://github.com/nlohmann/json)
```

---
